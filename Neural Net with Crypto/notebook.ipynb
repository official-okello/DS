{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26212691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1fcbcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60\n",
    "FUTURE_PERIOD_PREDICT = 3\n",
    "RATIO_TO_PREDICT = \"BTC-USD\"\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "NAME = f\"{RATIO_TO_PREDICT}-{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f53f6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ratios):\n",
    "    main_df = pd.DataFrame()\n",
    "    for ratio in ratios:\n",
    "        file_path = f'crypto_data/{ratio}.csv'\n",
    "        df = pd.read_csv(file_path, names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "        df.rename(columns={'close': f'close_{ratio}', 'volume': f'volume_{ratio}'}, inplace=True)\n",
    "        df.set_index('time', inplace=True)\n",
    "        df = df[[f'close_{ratio}', f'volume_{ratio}']]\n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df[[f'close_{ratio}', f'volume_{ratio}']])\n",
    "            main_df.fillna(method='ffill', inplace=True)\n",
    "            main_df.dropna(inplace=True)\n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76ea73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c372bf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m5/_3cx4z811590xl3t4m5tclmc0000gq/T/ipykernel_2739/960114981.py:13: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  main_df.fillna(method='ffill', inplace=True)\n",
      "/var/folders/m5/_3cx4z811590xl3t4m5tclmc0000gq/T/ipykernel_2739/960114981.py:13: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  main_df.fillna(method='ffill', inplace=True)\n",
      "/var/folders/m5/_3cx4z811590xl3t4m5tclmc0000gq/T/ipykernel_2739/960114981.py:13: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  main_df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Getting the data\n",
    "ratios = [\"BTC-USD\", \"ETH-USD\", \"LTC-USD\", \"BCH-USD\"]\n",
    "df = load_data(ratios)\n",
    "\n",
    "# Creating the target column\n",
    "df['future'] = df[f'close_{RATIO_TO_PREDICT}'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "df['target'] = list(map(classify, df[f'close_{RATIO_TO_PREDICT}'], df['future']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b57e8",
   "metadata": {},
   "source": [
    "Date Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5992e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into out_of_sample and in_sample\n",
    "times = sorted(df.index.values)\n",
    "last_5pct = times[-int(0.05*len(times))]\n",
    "\n",
    "validation_df = df[(df.index >= last_5pct)]\n",
    "df = df[(df.index < last_5pct)]\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = df.drop('future', axis=1)\n",
    "\n",
    "    # Scaling and normalizing the data\n",
    "    for col in df.columns:\n",
    "        if col != 'target':\n",
    "            df[col] = df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Creating sequences\n",
    "    sequential_data = []\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "\n",
    "    for c in df.values:\n",
    "        prev_days.append([n for n in c[:-1]])\n",
    "        if len(prev_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days), c[-1]])\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    # Balancing the data to have balanced classes\n",
    "    buys = []\n",
    "    sells = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq, target])\n",
    "        else:\n",
    "            buys.append([seq, target])\n",
    "    \n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "\n",
    "    lower = min(len(buys), len(sells))\n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "\n",
    "    sequential_data = buys + sells\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b980b",
   "metadata": {},
   "source": [
    "Building the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2e8d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocess_df(df)\n",
    "X_val, y_val = preprocess_df(validation_df)\n",
    "\n",
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(X_train.shape[1:])),\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.LSTM(128),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "    filepath = \"RNN_Final-{epoch:02d}-{val_accuracy:.3f}\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"models/{}.keras\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))\n",
    "    \n",
    "    return model, tensorboard, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facbb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    model, tensorboard, checkpoint = build_model()\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[tensorboard, checkpoint])\n",
    "    score = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print('Validation loss:', score[0])\n",
    "    print('Validation accuracy:', score[1])\n",
    "    model.save(f\"models/{NAME}.keras\")\n",
    "    accuracy = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    plt.plot(accuracy, label='accuracy')\n",
    "    plt.plot(loss, label='loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7781573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 174ms/step - accuracy: 0.5423 - loss: 0.7055 - val_accuracy: 0.5510 - val_loss: 0.6827\n",
      "Epoch 2/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 176ms/step - accuracy: 0.5704 - loss: 0.6778 - val_accuracy: 0.5774 - val_loss: 0.6764\n",
      "Epoch 3/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 176ms/step - accuracy: 0.5779 - loss: 0.6742 - val_accuracy: 0.5751 - val_loss: 0.6761\n",
      "Epoch 4/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 173ms/step - accuracy: 0.5849 - loss: 0.6720 - val_accuracy: 0.5827 - val_loss: 0.6740\n",
      "Epoch 5/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 167ms/step - accuracy: 0.5880 - loss: 0.6696 - val_accuracy: 0.5763 - val_loss: 0.6795\n",
      "Epoch 6/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 195ms/step - accuracy: 0.5941 - loss: 0.6668 - val_accuracy: 0.5756 - val_loss: 0.6793\n",
      "Epoch 7/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 197ms/step - accuracy: 0.5992 - loss: 0.6628 - val_accuracy: 0.5713 - val_loss: 0.6746\n",
      "Epoch 8/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 203ms/step - accuracy: 0.6092 - loss: 0.6562 - val_accuracy: 0.5745 - val_loss: 0.6779\n",
      "Epoch 9/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 208ms/step - accuracy: 0.6194 - loss: 0.6491 - val_accuracy: 0.5662 - val_loss: 0.6956\n",
      "Epoch 10/10\n",
      "\u001b[1m1300/1300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 201ms/step - accuracy: 0.6316 - loss: 0.6395 - val_accuracy: 0.5707 - val_loss: 0.6915\n",
      "Validation loss: 0.6915135383605957\n",
      "Validation accuracy: 0.5706619024276733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Sequential name=sequential_3, built=True>,\n",
       " <keras.src.callbacks.history.History at 0x12fa53050>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
